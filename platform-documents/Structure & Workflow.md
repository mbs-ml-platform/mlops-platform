## ğŸš€ Tá»•ng quan cáº¥u trÃºc Master Project (Polyrepo)

Thay vÃ¬ má»™t "siÃªu repo" duy nháº¥t, tÃ´i khuyáº¿n nghá»‹ sá»­ dá»¥ng kiáº¿n trÃºc **polyrepo**, nÆ¡i má»—i thÃ nh pháº§n chÃ­nh hoáº·c nhÃ³m chá»©c nÄƒng logic cá»§a ná»n táº£ng MLOps sáº½ náº±m trong má»™t repository Git riÃªng biá»‡t. CÃ¡ch tiáº¿p cáº­n nÃ y mang láº¡i nhiá»u lá»£i Ã­ch:

- **Quáº£n lÃ½ Ä‘á»™c láº­p:** Má»—i Ä‘á»™i (Data Engineering, ML Engineering, Data Science) cÃ³ thá»ƒ quáº£n lÃ½ vÃ²ng Ä‘á»i, phiÃªn báº£n, vÃ  quy trÃ¬nh CI/CD cá»§a riÃªng mÃ¬nh.
- **Kiá»ƒm soÃ¡t truy cáº­p chi tiáº¿t:** Dá»… dÃ ng cáº¥p quyá»n truy cáº­p khÃ¡c nhau cho tá»«ng repo.
- **Build vÃ  deploy nhanh hÆ¡n:** Chá»‰ nhá»¯ng thÃ nh pháº§n thay Ä‘á»•i má»›i cáº§n Ä‘Æ°á»£c build vÃ  deploy láº¡i.
- **Giáº£m thiá»ƒu xung Ä‘á»™t:** Ãt kháº£ nÄƒng xáº£y ra xung Ä‘á»™t khi nhiá»u ngÆ°á»i lÃ m viá»‡c trÃªn cÃ¡c pháº§n khÃ¡c nhau.

Master Project cá»§a báº¡n sáº½ lÃ  má»™t **khÃ¡i niá»‡m tá»• chá»©c** bao gá»“m cÃ¡c repo sau:

1. **`feature-store-management`**: Quáº£n lÃ½ Ä‘á»‹nh nghÄ©a features, pipelines xá»­ lÃ½ dá»¯ liá»‡u cho Feature Store, vÃ  cáº¥u hÃ¬nh Feast.
2. **`ml-model-development`**: NÆ¡i Data Scientists phÃ¡t triá»ƒn, huáº¥n luyá»‡n, vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ML.
3. **`ml-model-services`**: Chá»©a mÃ£ nguá»“n Ä‘á»ƒ Ä‘Ã³ng gÃ³i mÃ´ hÃ¬nh thÃ nh cÃ¡c API services (Model Service Layer & Label Engine Layer).
4. **`mlops-orchestration-pipelines`**: Äá»‹nh nghÄ©a cÃ¡c DAGs cho Apache Airflow (data pipelines, training pipelines, batch serving).
5. **`mlops-platform-infrastructure`**: MÃ£ nguá»“n Infrastructure as Code (IaC) vÃ  cáº¥u hÃ¬nh cho cÃ¡c cÃ´ng cá»¥ MLOps (MLFlow, Jenkins, Monitoring stack, cÆ¡ sá»Ÿ dá»¯ liá»‡u).
6. **`ml-reporting-and-monitoring-logic`**: MÃ£ nguá»“n cho viá»‡c xÃ¢y dá»±ng bÃ¡o cÃ¡o tÃ¹y chá»‰nh, dashboards, vÃ  cÃ¡c logic giÃ¡m sÃ¡t chuyÃªn sÃ¢u.

SÆ¡ Ä‘á»“ má»‘i quan há»‡ giá»¯a cÃ¡c Repo vÃ  Servers:

```
graph TD
    subgraph Developer Workstation
        Dev[Git Client]
    end

    subgraph Source Control (GitLab/GitHub)
        R1[Repo: feature-store-management]
        R2[Repo: ml-model-development]
        R3[Repo: ml-model-services]
        R4[Repo: mlops-orchestration-pipelines]
        R5[Repo: mlops-platform-infrastructure]
        R6[Repo: ml-reporting-and-monitoring-logic]
    end

    subgraph Server 1 (Data Processing & Feature Store Backend)
        S1_FS_Offline[PostgreSQL for Feast Offline]
        S1_MLFlow_Meta[PostgreSQL for MLFlow Metadata]
        S1_Spark[Apache Spark]
        S1_Kafka[Apache Kafka]
        S1_Feast_SDK[Feast SDK Consumers]
    end

    subgraph Server 2 (MLOps Orchestration & Management)
        S2_Airflow[Apache Airflow]
        S2_MLFlow_Server[MLFlow Server]
        S2_FS_Online[Redis for Feast Online]
        S2_Jenkins[Jenkins CI/CD]
        S2_Feast_Core[Feast Core Services]
    end

    subgraph Server 3 (Model Serving & Monitoring)
        S3_APIs[Model Serving APIs (FastAPI/Docker)]
        S3_Prometheus[Prometheus]
        S3_Grafana[Grafana]
        S3_ELK[ELK Stack]
    end

    Dev --> R1; Dev --> R2; Dev --> R3; Dev --> R4; Dev --> R5; Dev --> R6

    R1 --> S1_FS_Offline; R1 --> S2_FS_Online; R1 --> S2_Feast_Core
    R2 -- Training Data From --> S1_FS_Offline
    R2 -- Log Experiments/Models To --> S2_MLFlow_Server
    R3 -- Fetch Models From --> S2_MLFlow_Server
    R3 -- Fetch Online Features From --> S2_FS_Online
    R3 -- Deploy To --> S3_APIs
    R4 -- DAGs Deployed To --> S2_Airflow
    R5 -- IaC & Config For --> S1_FS_Offline; R5 -- IaC & Config For --> S1_MLFlow_Meta; R5 -- IaC & Config For --> S1_Spark; R5 -- IaC & Config For --> S1_Kafka
    R5 -- IaC & Config For --> S2_Airflow; R5 -- IaC & Config For --> S2_MLFlow_Server; R5 -- IaC & Config For --> S2_FS_Online; R5 -- IaC & Config For --> S2_Jenkins
    R5 -- IaC & Config For --> S3_APIs; R5 -- IaC & Config For --> S3_Prometheus; R5 -- IaC & Config For --> S3_Grafana; R5 -- IaC & Config For --> S3_ELK
    R6 -- Dashboards/Reports For --> S3_Grafana; R6 -- Dashboards/Reports For --> S3_ELK; R6 -- Consumes Data From --> S2_MLFlow_Server; R6 -- Consumes Data From --> S3_Prometheus

    S2_Jenkins -- Builds & Deploys --> R1; S2_Jenkins -- Builds & Deploys --> R2; S2_Jenkins -- Builds & Deploys --> R3; S2_Jenkins -- Builds & Deploys --> R4; S2_Jenkins -- Builds & Deploys --> R5; S2_Jenkins -- Builds & Deploys --> R6
    S2_Airflow -- Orchestrates Tasks Involving --> S1_Spark; S2_Airflow -- Orchestrates Tasks Involving --> S1_FS_Offline; S2_Airflow -- Orchestrates Tasks Involving --> S2_FS_Online; S2_Airflow -- Orchestrates Tasks Involving --> S2_MLFlow_Server
    S3_APIs -- Metrics To --> S3_Prometheus; S3_APIs -- Logs To --> S3_ELK
```

---

## ğŸ›ï¸ Cáº¥u trÃºc chi tiáº¿t cÃ¡c Repository

### 1. Repo: `feature-store-management`

Quáº£n lÃ½ má»i thá»© liÃªn quan Ä‘áº¿n Feature Store.

```
feature-store-management/
â”œâ”€â”€ feast_repository/              # ThÆ° má»¥c gá»‘c cho `feast apply` vÃ  `feast materialize`
â”‚   â”œâ”€â”€ entities.py                # Äá»‹nh nghÄ©a Entities (user, item, etc.)
â”‚   â”œâ”€â”€ data_sources.py            # Äá»‹nh nghÄ©a Data Sources (trá» Ä‘áº¿n DWH, Data Lake, Kafka topics)
â”‚   â”œâ”€â”€ feature_views/             # Äá»‹nh nghÄ©a Feature Views
â”‚   â”‚   â”œâ”€â”€ user_profile_features.py
â”‚   â”‚   â”œâ”€â”€ transaction_agg_features.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ feature_services/          # (TÃ¹y chá»n) Äá»‹nh nghÄ©a Feature Services
â”‚   â”‚   â””â”€â”€ credit_scoring_service_features.py
â”‚   â””â”€â”€ feature_store.yaml         # Cáº¥u hÃ¬nh chÃ­nh cá»§a Feast (registry, provider, online/offline stores)
â”œâ”€â”€ data_transformation_pipelines/ # Scripts/dbt models Ä‘á»ƒ chuáº©n bá»‹ dá»¯ liá»‡u cho Feast
â”‚   â”œâ”€â”€ dbt_project_feast/         # Náº¿u dÃ¹ng dbt Ä‘á»ƒ transform dá»¯ liá»‡u nguá»“n thÃ nh báº£ng cho Feast
â”‚   â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”‚   â”œâ”€â”€ models/                # dbt models: staging, intermediate, marts (feature tables)
â”‚   â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ stg_transactions.sql
â”‚   â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”‚   â”‚       â””â”€â”€ fct_user_daily_spend.sql
â”‚   â”‚   â””â”€â”€ profiles.yml.template
â”‚   â”œâ”€â”€ spark_jobs_feast/          # Spark jobs náº¿u dÃ¹ng Spark cho data transformation
â”‚   â”‚   â””â”€â”€ process_market_stream.py
â”‚   â””â”€â”€ python_scripts_feast/      # Python scripts cho cÃ¡c tÃ¡c vá»¥ ETL nhá»
â”‚       â””â”€â”€ clean_user_demographics.py
â”œâ”€â”€ notebooks_feature_dev/         # Jupyter notebooks cho EDA, profiling, feature engineering
â”‚   â”œâ”€â”€ 01_eda_raw_transactions.ipynb
â”‚   â”œâ”€â”€ 02_profiling_market_data.ipynb
â”‚   â”œâ”€â”€ 03_feature_engineering_user_behavior.ipynb
â”‚   â””â”€â”€ common_utils/              # Tiá»‡n Ã­ch cho notebooks
â”‚       â””â”€â”€ data_loading.py
â”œâ”€â”€ data_source_connectors/        # MÃ£ nguá»“n káº¿t ná»‘i Ä‘áº¿n cÃ¡c há»‡ thá»‘ng dá»¯ liá»‡u (DWH, Data Lake, API)
â”‚   â”œâ”€â”€ database_connector.py
â”‚   â”œâ”€â”€ kafka_consumer_utils.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ connections.ini.template # Template, secrets quáº£n lÃ½ riÃªng
â”œâ”€â”€ tests/                         # Unit tests cho data transformations, feature definitions
â”‚   â”œâ”€â”€ test_dbt_models.py
â”‚   â”œâ”€â”€ test_feature_view_logic.py
â”‚   â””â”€â”€ common_test_utils.py
â”œâ”€â”€ scripts/                       # Scripts tiá»‡n Ã­ch (deploy, materialize)
â”‚   â”œâ”€â”€ run_feast_apply.sh
â”‚   â”œâ”€â”€ run_feast_materialize_incremental.sh
â”‚   â””â”€â”€ run_dbt_for_feast.sh
â”œâ”€â”€ Dockerfile.feast_cli           # (TÃ¹y chá»n) Dockerfile Ä‘á»ƒ cháº¡y Feast CLI trong CI/CD
â”œâ”€â”€ requirements.txt               # Python dependencies (feast, pandas, pyspark, dbt-postgres, etc.)
â””â”€â”€ README.md
```

### 2. Repo: `ml-model-development`

NÆ¡i Data Scientists phÃ¡t triá»ƒn, huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh.

```
ml-model-development/
â”œâ”€â”€ models/                        # Má»—i sub-folder lÃ  má»™t dá»± Ã¡n/loáº¡i mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ fraud_detection_xgboost/
â”‚   â”‚   â”œâ”€â”€ notebooks/             # Notebooks cho EDA, thá»­ nghiá»‡m, model building
â”‚   â”‚   â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ 02_feature_selection_and_preprocessing.ipynb
â”‚   â”‚   â”‚   â””â”€â”€ 03_xgboost_training_and_evaluation.ipynb
â”‚   â”‚   â”œâ”€â”€ src/                   # MÃ£ nguá»“n chÃ­nh thá»©c cho mÃ´ hÃ¬nh
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py          # Cáº¥u hÃ¬nh (Pydantic model): hyperparameters, feature list
â”‚   â”‚   â”‚   â”œâ”€â”€ data_loader.py     # Táº£i data tá»« Feature Store, xá»­ lÃ½ label
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessor.py    # Tiá»n xá»­ lÃ½ feature Ä‘áº·c thÃ¹ (sau khi láº¥y tá»« Feature Store)
â”‚   â”‚   â”‚   â”œâ”€â”€ train.py           # Script huáº¥n luyá»‡n, log vÃ o MLFlow
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluate.py        # Script Ä‘Ã¡nh giÃ¡, so sÃ¡nh model
â”‚   â”‚   â”‚   â””â”€â”€ predict_batch.py   # (TÃ¹y chá»n) Script cho dá»± Ä‘oÃ¡n batch
â”‚   â”‚   â”œâ”€â”€ tests/                 # Unit tests cho src/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_preprocessor.py
â”‚   â”‚   â”‚   â””â”€â”€ test_data_loader.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt       # Dependencies riÃªng cho model nÃ y
â”‚   â”‚   â””â”€â”€ Dockerfile.train       # (TÃ¹y chá»n) Náº¿u cáº§n mÃ´i trÆ°á»ng huáº¥n luyá»‡n Ä‘áº·c biá»‡t
â”‚   â”œâ”€â”€ customer_churn_lightgbm/
â”‚   â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ src/                   # TÆ°Æ¡ng tá»± nhÆ° trÃªn
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ ...
â”œâ”€â”€ common_ml_utils/               # CÃ¡c hÃ m, lá»›p tiá»‡n Ã­ch dÃ¹ng chung cho nhiá»u mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model_trainer.py      # Abstract Base Class cho trainer (káº¿ thá»«a)
â”‚   â”œâ”€â”€ data_schemas/              # Pydantic models cho cáº¥u trÃºc dá»¯ liá»‡u dÃ¹ng chung
â”‚   â”‚   â””â”€â”€ training_data_contract.py
â”‚   â”œâ”€â”€ evaluation_utils.py        # CÃ¡c hÃ m Ä‘Ã¡nh giÃ¡ tÃ¹y chá»‰nh
â”‚   â”œâ”€â”€ feature_store_client.py    # Helper Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i Feature Store
â”‚   â””â”€â”€ mlflow_utils.py            # Helper Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vá»›i MLFlow
â”œâ”€â”€ research_and_poc/              # Cho cÃ¡c thá»­ nghiá»‡m, PoC chÆ°a chÃ­nh thá»©c
â”‚   â””â”€â”€ new_nlp_approach.ipynb
â”œâ”€â”€ requirements_common.txt        # Dependencies chung (Ã­t khi dÃ¹ng, Æ°u tiÃªn trong tá»«ng model)
â””â”€â”€ README.md
```

### 3. Repo: `ml-model-services`

ÄÃ³ng gÃ³i mÃ´ hÃ¬nh thÃ nh API services.

```
ml-model-services/
â”œâ”€â”€ services/                       # Má»—i sub-folder lÃ  má»™t microservice cho má»™t mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ fraud_detection_api/
â”‚   â”‚   â”œâ”€â”€ app/                    # MÃ£ nguá»“n FastAPI/Flask
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI app, API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic schemas cho request/response
â”‚   â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ config.py       # Cáº¥u hÃ¬nh service (MLFlow URI, model name/stage)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ model_handler.py # Táº£i model tá»« MLFlow, gá»i Feature Store online
â”‚   â”‚   â”‚   â”œâ”€â”€ business_logic/     # Model Service Layer & Label Engine Layer
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ fraud_processing.py # Tiá»n xá»­ lÃ½, gá»i model, háº­u xá»­ lÃ½, Ã¡p dá»¥ng rules
â”‚   â”‚   â”‚   â””â”€â”€ dependencies.py     # (TÃ¹y chá»n) FastAPI dependencies
â”‚   â”‚   â”œâ”€â”€ tests/                  # Unit/Integration tests cho API
â”‚   â”‚   â”‚   â”œâ”€â”€ test_api_endpoints.py
â”‚   â”‚   â”‚   â””â”€â”€ test_fraud_processing.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile              # Dockerfile Ä‘á»ƒ Ä‘Ã³ng gÃ³i service
â”‚   â”‚   â”œâ”€â”€ requirements.txt        # Dependencies (fastapi, uvicorn, mlflow-skinny, feast)
â”‚   â”‚   â””â”€â”€ deployment_configs/     # (TÃ¹y chá»n) Kubernetes manifests, docker-compose.yml
â”‚   â”‚       â””â”€â”€ kubernetes_deployment.yaml
â”‚   â”œâ”€â”€ customer_churn_api/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â””â”€â”€ ...                 # TÆ°Æ¡ng tá»±
â”‚   â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ ...
â”œâ”€â”€ common_service_libs/            # ThÆ° viá»‡n dÃ¹ng chung cho cÃ¡c model services
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_api_config.py        # Pydantic BaseSettings cho cáº¥u hÃ¬nh chung
â”‚   â”œâ”€â”€ error_handlers.py         # Xá»­ lÃ½ lá»—i chung
â”‚   â”œâ”€â”€ monitoring_middleware.py  # Middleware Ä‘á»ƒ expose Prometheus metrics
â”‚   â””â”€â”€ auth_utils.py             # (TÃ¹y chá»n) Logic xÃ¡c thá»±c API
â”œâ”€â”€ Dockerfile.base_service         # (TÃ¹y chá»n) Base Docker image náº¿u nhiá»u service dÃ¹ng chung libs náº·ng
â””â”€â”€ README.md
```

### 4. Repo: `mlops-orchestration-pipelines`

Äá»‹nh nghÄ©a cÃ¡c DAGs cho Apache Airflow.

```
mlops-orchestration-pipelines/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ data_ingestion_and_feature_store/ # DAGs cho Feature Store
â”‚   â”‚   â”œâ”€â”€ run_dbt_feast_models_dag.py
â”‚   â”‚   â”œâ”€â”€ materialize_feast_online_store_dag.py
â”‚   â”‚   â””â”€â”€ stream_market_data_to_feast_dag.py # Náº¿u cÃ³ streaming
â”‚   â”œâ”€â”€ model_training_pipelines/           # DAGs cho huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”‚   â”‚   â”œâ”€â”€ train_fraud_detection_xgboost_dag.py
â”‚   â”‚   â””â”€â”€ train_customer_churn_lightgbm_dag.py
â”‚   â”œâ”€â”€ batch_inference_pipelines/          # DAGs cho dá»± Ä‘oÃ¡n batch
â”‚   â”‚   â””â”€â”€ score_daily_transactions_fraud_dag.py
â”‚   â”œâ”€â”€ model_monitoring_pipelines/         # DAGs cho giÃ¡m sÃ¡t (drift detection, retraining trigger)
â”‚   â”‚   â””â”€â”€ check_fraud_model_drift_dag.py
â”‚   â””â”€â”€ utility_dags/
â”‚       â””â”€â”€ backup_mlflow_db_dag.py
â”œâ”€â”€ plugins/                                # Custom Airflow plugins (operators, hooks, sensors)
â”‚   â”œâ”€â”€ operators/
â”‚   â”‚   â””â”€â”€ feast_materialize_operator.py   # VÃ­ dá»¥
â”‚   â””â”€â”€ hooks/
â”‚       â””â”€â”€ internal_api_hook.py
â”œâ”€â”€ config/                                 # Cáº¥u hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c load bá»Ÿi DAGs (Ã­t dÃ¹ng)
â”‚   â””â”€â”€ pipeline_variables.json
â”œâ”€â”€ tests/                                  # Tests cho DAGs (DAG integrity, task dependencies)
â”‚   â”œâ”€â”€ test_dag_definitions.py
â”‚   â””â”€â”€ test_training_pipeline_flow.py
â”œâ”€â”€ Dockerfile.airflow_custom_worker        # Dockerfile cho custom Airflow worker image (náº¿u cáº§n)
â”œâ”€â”€ requirements_airflow.txt                # Python dependencies cho mÃ´i trÆ°á»ng Airflow worker
â””â”€â”€ README.md
```

### 5. Repo: `mlops-platform-infrastructure`

MÃ£ nguá»“n IaC vÃ  cáº¥u hÃ¬nh cho cÃ¡c cÃ´ng cá»¥ ná»n táº£ng.

```
mlops-platform-infrastructure/
â”œâ”€â”€ terraform/                            # Hoáº·c Ansible, Pulumi
â”‚   â”œâ”€â”€ environments/                     # Cáº¥u hÃ¬nh cho tá»«ng mÃ´i trÆ°á»ng (dev, staging, prod)
â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”‚   â””â”€â”€ variables.tf
â”‚   â”‚   â””â”€â”€ prod/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”œâ”€â”€ modules/                          # Terraform modules tÃ¡i sá»­ dá»¥ng (server, postgres, redis, airflow)
â”‚   â”‚   â”œâ”€â”€ compute_instance/
â”‚   â”‚   â”œâ”€â”€ postgresql_server/
â”‚   â”‚   â”œâ”€â”€ redis_cluster/
â”‚   â”‚   â””â”€â”€ airflow_on_docker/
â”‚   â””â”€â”€ backend_config.tf                 # Cáº¥u hÃ¬nh remote state
â”œâ”€â”€ docker_compose_setups/                # Docker Compose files cho dev/local hoáº·c non-Kubernetes setups
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ mlflow_server/
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ feature_store_backend/            # Postgres & Redis cho Feast
â”‚   â”‚   â””â”€â”€ docker-compose.yml
â”‚   â””â”€â”€ monitoring_stack/                 # Prometheus, Grafana, ELK
â”‚       â””â”€â”€ docker-compose.yml
â”œâ”€â”€ jenkins_config/                       # Cáº¥u hÃ¬nh Jenkins
â”‚   â”œâ”€â”€ Jenkinsfile_feature_store         # Pipeline as Code cho repo feature-store-management
â”‚   â”œâ”€â”€ Jenkinsfile_ml_model_development
â”‚   â”œâ”€â”€ Jenkinsfile_ml_model_services
â”‚   â”œâ”€â”€ Jenkinsfile_mlops_orchestration
â”‚   â”œâ”€â”€ Jenkinsfile_platform_infra        # CI/CD cho chÃ­nh repo nÃ y
â”‚   â”œâ”€â”€ Jenkinsfile_reporting_monitoring
â”‚   â”œâ”€â”€ jobs_dsl/                         # (TÃ¹y chá»n) Náº¿u dÃ¹ng Job DSL plugin
â”‚   â””â”€â”€ initial_config/
â”‚       â””â”€â”€ plugins.txt                   # Danh sÃ¡ch plugin cáº§n cÃ i
â”œâ”€â”€ kubernetes_deployments/               # (Náº¿u dÃ¹ng Kubernetes) Manifests cho cÃ¡c thÃ nh pháº§n
â”‚   â”œâ”€â”€ airflow_cluster/
â”‚   â”œâ”€â”€ mlflow_on_k8s/
â”‚   â”œâ”€â”€ model_service_templates/
â”‚   â””â”€â”€ monitoring_on_k8s/
â”œâ”€â”€ server_provisioning_scripts/          # Scripts Ä‘á»ƒ bootstrap server váº­t lÃ½/VM (náº¿u khÃ´ng dÃ¹ng IaC hoÃ n toÃ n)
â”‚   â”œâ”€â”€ setup_server1_dataproc.sh
â”‚   â”œâ”€â”€ setup_server2_orchestration.sh
â”‚   â””â”€â”€ setup_server3_serving.sh
â”œâ”€â”€ platform_config_templates/            # File cáº¥u hÃ¬nh template cho cÃ¡c dá»‹ch vá»¥
â”‚   â”œâ”€â”€ airflow/airflow.cfg.j2
â”‚   â”œâ”€â”€ prometheus/prometheus.yml.j2
â”‚   â””â”€â”€ grafana/provisioning_templates/
â”‚       â”œâ”€â”€ dashboards.yml.j2
â”‚       â””â”€â”€ datasources.yml.j2
â””â”€â”€ README.md
```

### 6. Repo: `ml-reporting-and-monitoring-logic`

MÃ£ nguá»“n cho bÃ¡o cÃ¡o, dashboards tÃ¹y chá»‰nh, vÃ  logic giÃ¡m sÃ¡t chuyÃªn sÃ¢u.

```
ml-reporting-and-monitoring-logic/
â”œâ”€â”€ dashboards_as_code/                # Äá»‹nh nghÄ©a dashboards (JSON cho Grafana, NDJSON cho Kibana)
â”‚   â”œâ”€â”€ grafana_dashboards/
â”‚   â”‚   â”œâ”€â”€ overview_model_performance.json
â”‚   â”‚   â”œâ”€â”€ feature_drift_analysis.json
â”‚   â”‚   â””â”€â”€ system_health_overview.json
â”‚   â””â”€â”€ kibana_dashboards/
â”‚       â””â”€â”€ api_error_and_latency_analysis.ndjson
â”œâ”€â”€ custom_reports/                    # Scripts/notebooks Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o Ä‘á»‹nh ká»³, ad-hoc
â”‚   â”œâ”€â”€ generate_monthly_model_retraining_report.py
â”‚   â”œâ”€â”€ adhoc_customer_segment_prediction_analysis.ipynb
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ db_query_for_reports.py
â”œâ”€â”€ alerting_configurations/           # (TÃ¹y chá»n) Äá»‹nh nghÄ©a alert rules cho Prometheus Alertmanager
â”‚   â”œâ”€â”€ model_specific_alerts.yml
â”‚   â””â”€â”€ system_critical_alerts.yml
â”œâ”€â”€ advanced_monitoring_scripts/       # Scripts cho cÃ¡c tÃ¡c vá»¥ giÃ¡m sÃ¡t phá»©c táº¡p
â”‚   â”œâ”€â”€ calculate_concept_drift_scores.py
â”‚   â””â”€â”€ analyze_prediction_bias.py
â”œâ”€â”€ requirements.txt                   # Dependencies (pandas, matplotlib, grafana_api, elasticsearch-dsl)
â””â”€â”€ README.md
```

---

## ğŸ”„ Workflow chi tiáº¿t vÃ  vá»‹ trÃ­ thá»±c hiá»‡n

### 1. Khi cÃ³ nguá»“n dá»¯ liá»‡u má»›i hoáº·c thÃªm feature trong Feature Store, EDA, Feature Engineering

- **NgÆ°á»i thá»±c hiá»‡n**: Data Engineer, Data Scientist.
- **Repo chÃ­nh**: `feature-store-management`.
- **CÃ¡c bÆ°á»›c vÃ  vá»‹ trÃ­:**
    1. **Káº¿t ná»‘i nguá»“n dá»¯ liá»‡u má»›i**:
        - Náº¿u cáº§n code connector má»›i: `feature-store-management/data_source_connectors/`.
        - Cáº¥u hÃ¬nh connection (khÃ´ng commit secret): `feature-store-management/data_source_connectors/config/`.
    2. **EDA vÃ  Profiling dá»¯ liá»‡u nguá»“n**:
        - Thá»±c hiá»‡n trong: `feature-store-management/notebooks_feature_dev/`. Sá»­ dá»¥ng connector á»Ÿ trÃªn.
    3. **Thá»­ nghiá»‡m Feature Engineering**:
        - Tiáº¿p tá»¥c trong: `feature-store-management/notebooks_feature_dev/`.
    4. **Triá»ƒn khai Data Transformation Pipelines**:
        - Viáº¿t dbt models: `feature-store-management/data_transformation_pipelines/dbt_project_feast/models/`.
        - Hoáº·c Spark jobs: `feature-store-management/data_transformation_pipelines/spark_jobs_feast/`.
        - Hoáº·c Python scripts: `feature-store-management/data_transformation_pipelines/python_scripts_feast/`.
    5. **Äá»‹nh nghÄ©a Features trong Feast**:
        - Cáº­p nháº­t/táº¡o file trong: `feature-store-management/feast_repository/feature_views/`, `entities.py`, `data_sources.py`.
        - Cáº­p nháº­t `feature_store.yaml` náº¿u cáº§n.
    6. **Viáº¿t Tests**:
        - `feature-store-management/tests/`.
    7. **Commit & Push**: LÃªn repo `feature-store-management`.
    8. **CI/CD (Jenkins)**:
        - Trigger `Jenkinsfile_feature_store` (tá»« `mlops-platform-infrastructure/jenkins_config/`).
        - Cháº¡y tests.
        - Cháº¡y `dbt run` (náº¿u cÃ³).
        - Cháº¡y `feast apply` (sá»­ dá»¥ng `feature-store-management/scripts/run_feast_apply.sh`).
    9. **Orchestration (Airflow)**:
        - DAGs trong `mlops-orchestration-pipelines/dags/data_ingestion_and_feature_store/` sáº½ Ä‘Æ°á»£c trigger (theo lá»‹ch hoáº·c sá»± kiá»‡n) Ä‘á»ƒ cháº¡y cÃ¡c data transformation pipelines vÃ  `feast materialize` (sá»­ dá»¥ng `mlops-orchestration-pipelines/plugins/operators/feast_materialize_operator.py` náº¿u báº¡n táº¡o custom operator, hoáº·c PythonOperator vá»›i Feast SDK).

### 2. Khi xÃ¢y 1 mÃ´ hÃ¬nh má»›i: Láº¥y feature, Ä‘Ã¡nh giÃ¡, build model, train, build train pipeline, bÃ¡o cÃ¡o, Ä‘Ã³ng gÃ³i

- **NgÆ°á»i thá»±c hiá»‡n**: Data Scientist, ML Engineer.
- **Repo chÃ­nh**: `ml-model-development`, `mlops-orchestration-pipelines`.
- **CÃ¡c bÆ°á»›c vÃ  vá»‹ trÃ­:**
    1. **Táº¡o thÆ° má»¥c dá»± Ã¡n model má»›i**:
        - Trong `ml-model-development/models/your_new_model_project/`.
    2. **EDA, Feature Selection, Model Prototyping**:
        - Trong `ml-model-development/models/your_new_model_project/notebooks/`.
        - Sá»­ dá»¥ng `ml-model-development/common_ml_utils/feature_store_client.py` Ä‘á»ƒ láº¥y data tá»« Feast.
        - Log cÃ¡c thá»­ nghiá»‡m ban Ä‘áº§u lÃªn MLFlow Tracking Server (Server 2) báº±ng `mlflow.start_run()`.
    3. **Viáº¿t mÃ£ nguá»“n huáº¥n luyá»‡n chÃ­nh thá»©c**:
        - Trong `ml-model-development/models/your_new_model_project/src/`.
        - `config.py`: DÃ¹ng Pydantic, káº¿ thá»«a tá»« `BaseSettings` Ä‘á»ƒ load params tá»« env, file.
        - `train.py`: Script chÃ­nh, sá»­ dá»¥ng MLFlow Ä‘á»ƒ log metrics, params, model artifact (`mlflow.log_model`).
        - Káº¿ thá»«a base model tá»« `ml-model-development/common_ml_utils/base_model_trainer.py`.
    4. **Viáº¿t Tests**:
        - `ml-model-development/models/your_new_model_project/tests/`.
    5. **Commit & Push**: LÃªn repo `ml-model-development`.
    6. **CI (Jenkins)**:
        - Trigger `Jenkinsfile_ml_model_development`.
        - Cháº¡y tests, linting. (KhÃ´ng train á»Ÿ Ä‘Ã¢y, chá»‰ build/test code).
    7. **XÃ¢y dá»±ng Training Pipeline (Airflow DAG)**:
        - **ML Engineer/Data Scientist** táº¡o DAG má»›i trong `mlops-orchestration-pipelines/dags/model_training_pipelines/`.
        - DAG sáº½:
            - Checkout code tá»« repo `ml-model-development` (phiÃªn báº£n cá»¥ thá»ƒ).
            - Chuáº©n bá»‹ mÃ´i trÆ°á»ng huáº¥n luyá»‡n (cÃ³ thá»ƒ dÃ¹ng KubernetesPodOperator, DockerOperator).
            - Cháº¡y script `train.py` tá»« repo `ml-model-development`. Script nÃ y sáº½ tá»± log model lÃªn MLFlow Model Registry (Server 2).
            - (TÃ¹y chá»n) Cháº¡y `evaluate.py`, gá»­i thÃ´ng bÃ¡o.
    8. **Commit & Push DAG**: LÃªn repo `mlops-orchestration-pipelines`.
    9. **CI/CD cho DAGs (Jenkins)**:
        - Trigger `Jenkinsfile_mlops_orchestration`.
        - Test DAG, deploy lÃªn Airflow (Server 2).
    10. **Xuáº¥t bÃ¡o cÃ¡o phÃ¡t triá»ƒn**:
        - Notebooks Ä‘Ã£ dÃ¹ng cÃ³ thá»ƒ Ä‘Æ°á»£c dá»n dáº¹p, xuáº¥t ra HTML/PDF.
        - Hoáº·c táº¡o script bÃ¡o cÃ¡o trong `ml-reporting-and-monitoring-logic/custom_reports/` Ä‘á»ƒ query MLFlow.
    11. **ÄÃ³ng gÃ³i lÆ°u trá»¯ mÃ´ hÃ¬nh**:
        - MLFlow Model Registry (Server 2) Ä‘Ã£ tá»± Ä‘á»™ng lÃ m viá»‡c nÃ y khi `train.py` cháº¡y `mlflow.log_model(..., registered_model_name="your_model_name")`.

### 3. Triá»ƒn khai mÃ´ hÃ¬nh (production, service, batch, online)

- **NgÆ°á»i thá»±c hiá»‡n**: ML Engineer, DevOps Engineer.
    
- **Repo chÃ­nh**: `ml-model-services`, `mlops-orchestration-pipelines` (cho batch).
    
- **CÃ¡c bÆ°á»›c vÃ  vá»‹ trÃ­:**
    
    **A. Triá»ƒn khai Online Service (API):**
    
    1. **PhÃ¡t triá»ƒn Model Service API**:
        - Trong `ml-model-services/services/your_model_api/`.
        - `app/core/model_handler.py`: Load model tá»« MLFlow Model Registry (phiÃªn báº£n Ä‘Ã£ Ä‘Æ°á»£c duyá»‡t, vÃ­ dá»¥: "Production" stage).
        - `app/business_logic/your_processing.py`: Implement Model Service Layer (tiá»n xá»­ lÃ½ input API, gá»i Feature Store online qua Feast SDK, gá»i model) vÃ  Label Engine Layer (Ã¡p dá»¥ng business rules).
        - `Dockerfile` Ä‘á»ƒ Ä‘Ã³ng gÃ³i.
    2. **Commit & Push**: LÃªn repo `ml-model-services`.
    3. **CI/CD (Jenkins)**:
        - Trigger `Jenkinsfile_ml_model_services`.
        - Cháº¡y tests.
        - Build Docker image.
        - Push image lÃªn Container Registry (náº¿u cÃ³) hoáº·c Server 3.
        - Deploy lÃªn Staging (náº¿u cÃ³), cháº¡y smoke tests.
        - Deploy lÃªn Production (Server 3) dÃ¹ng Docker Compose (tá»« `mlops-platform-infrastructure/docker_compose_setups/`) hoáº·c Kubernetes manifests (tá»« `mlops-platform-infrastructure/kubernetes_deployments/` hoáº·c `ml-model-services/services/your_model_api/deployment_configs/`).
    
    **B. Triá»ƒn khai Batch Serving:**
    
    4. **XÃ¢y dá»±ng Batch Inference Pipeline (Airflow DAG)**:
        - Trong `mlops-orchestration-pipelines/dags/batch_inference_pipelines/`.
        - DAG sáº½: Láº¥y dá»¯ liá»‡u batch, láº¥y features tá»« Feast Offline Store, táº£i model tá»« MLFlow Model Registry, cháº¡y dá»± Ä‘oÃ¡n, Ã¡p dá»¥ng Label Engine, lÆ°u káº¿t quáº£.
    5. **Commit & Push DAG**: LÃªn repo `mlops-orchestration-pipelines`.
    6. **CI/CD cho DAGs**: Deploy lÃªn Airflow (Server 2).

### 4. Äiá»u phá»‘i Airflow

- **Repo**: `mlops-orchestration-pipelines` (Ä‘á»‹nh nghÄ©a DAGs), `mlops-platform-infrastructure` (cáº¥u hÃ¬nh Airflow).
- **Airflow cá»§a Feature Store**: CÃ¡c DAGs trong `mlops-orchestration-pipelines/dags/data_ingestion_and_feature_store/` sáº½ Ä‘iá»u phá»‘i cÃ¡c pipeline dá»¯ liá»‡u cho Feast. ChÃºng sá»­ dá»¥ng Feast SDK (cÃ i trong mÃ´i trÆ°á»ng worker cá»§a Airflow) Ä‘á»ƒ trigger `materialize`.
- **Airflow Worker Environment**: `mlops-orchestration-pipelines/Dockerfile.airflow_custom_worker` vÃ  `requirements_airflow.txt` Ä‘á»‹nh nghÄ©a mÃ´i trÆ°á»ng cho worker (bao gá»“m Feast SDK, MLFlow client, cÃ¡c thÆ° viá»‡n DB,...).

### 5. PhÃ¡t triá»ƒn thá»­ nghiá»‡m 1 service má»›i

- **Repo**: `ml-model-services` (náº¿u lÃ  model API) hoáº·c táº¡o repo má»›i náº¿u lÃ  service Ä‘á»™c láº­p.
- **Local Development**: DÃ¹ng Docker Compose tá»« `mlops-platform-infrastructure/docker_compose_setups/`Ä‘á»ƒ dá»±ng cÃ¡c dependencies (DB giáº£ láº­p, MLFlow local).

### 6. Trigger cÃ¡c luá»“ng CI/CD

- **CÃ´ng cá»¥**: Jenkins (Server 2).
- **Trigger**: Webhooks tá»« Git (push, merge), manual trigger, scheduled.
- **Äá»‹nh nghÄ©a Pipelines**: CÃ¡c `Jenkinsfile_*` trong `mlops-platform-infrastructure/jenkins_config/`.

### 7. XÃ¢y dá»±ng cÃ¡c bÃ¡o cÃ¡o má»›i, monitoring model má»›i

- **Repo**: `ml-reporting-and-monitoring-logic`.
- **Dashboards**: Táº¡o/cáº­p nháº­t JSON/NDJSON trong `dashboards_as_code/`. CI/CD cá»§a repo nÃ y sáº½ dÃ¹ng Grafana/Kibana API Ä‘á»ƒ deploy.
- **Custom Reports**: Viáº¿t scripts/notebooks trong `custom_reports/`. CÃ³ thá»ƒ Ä‘Æ°á»£c trigger bá»Ÿi Airflow DAGs trong `mlops-orchestration-pipelines/dags/utility_dags/`.
- **Model Service Metrics**: Logic expose metrics náº±m trong code cá»§a tá»«ng service (`ml-model-services/.../monitoring_middleware.py`). Prometheus (Server 3) cÃ o cÃ¡c endpoint nÃ y. Alert rules cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a trong `ml-reporting-and-monitoring-logic/alerting_configurations/` vÃ  Ä‘Æ°á»£c apply vÃ o Prometheus/Alertmanager.

---

## ğŸ“Œ LÃ m rÃµ cÃ¡c Ä‘iá»ƒm khÃ¡c

1. **Feature Store Profiling/EDA vÃ  Feature Engineering**:
    
    - ÄÃºng nhÆ° báº¡n muá»‘n, viá»‡c nÃ y náº±m trong **`feature-store-management`**.
    - **Profiling/EDA**: `notebooks_feature_dev/` sá»­ dá»¥ng Pandas, PySpark, cÃ¡c thÆ° viá»‡n profiling.
    - **Feature Engineering**: Ã tÆ°á»Ÿng tá»« notebooks sáº½ Ä‘Æ°á»£c hiá»‡n thá»±c hÃ³a trong `data_transformation_pipelines/` (dbt, Spark).
    - **Feast**: Chá»‰ lÆ°u trá»¯ features Ä‘Ã£ Ä‘Æ°á»£c tÃ­nh toÃ¡n.
    - **Clean/Aggregate nháº¹ theo thá»i gian**: CÃ³ thá»ƒ lÃ m trong dbt/Spark trÆ°á»›c khi ingest vÃ o Feast, hoáº·c dÃ¹ng on-demand transformations cá»§a Feast náº¿u phÃ¹ há»£p.
    - **Category preprocessing**: Äá»ƒ trong `ml-model-development/models/.../src/preprocessor.py` lÃ  há»£p lÃ½ Ä‘á»ƒ trÃ¡nh phÃ¬nh dá»¯ liá»‡u Feature Store.
2. **Viáº¿t data connection má»›i, profiling, EDA rá»“i má»›i quyáº¿t Ä‘á»‹nh feature engineering**:
    
    - ChÃ­nh xÃ¡c, quy trÃ¬nh nÃ y diá»…n ra trong **`feature-store-management`**.
        1. ThÃªm/cáº­p nháº­t connector trong `data_source_connectors/`.
        2. DÃ¹ng connector Ä‘Ã³ trong `notebooks_feature_dev/` Ä‘á»ƒ profiling, EDA.
        3. Dá»±a trÃªn káº¿t quáº£, quyáº¿t Ä‘á»‹nh logic feature engineering vÃ  implement trong `data_transformation_pipelines/`, sau Ä‘Ã³ Ä‘á»‹nh nghÄ©a feature views trong `feast_repository/`.
3. **Thiáº¿t káº¿ base model, káº¿ thá»«a, data model (Pydantic), `settings.py`**:
    
    - **Base Model (cho logic huáº¥n luyá»‡n)**: `ml-model-development/common_ml_utils/base_model_trainer.py`. CÃ¡c model cá»¥ thá»ƒ sáº½ káº¿ thá»«a tá»« Ä‘Ã¢y.
    - **Data Model (Pydantic)**:
        - Cho cáº¥u trÃºc dá»¯ liá»‡u chung (vÃ­ dá»¥: training data contract): `ml-model-development/common_ml_utils/data_schemas/`.
        - Cho request/response API: Trong tá»«ng service API, vÃ­ dá»¥ `ml-model-services/services/fraud_detection_api/app/schemas.py`.
        - Cho cáº¥u hÃ¬nh: DÃ¹ng Pydantic `BaseSettings` trong cÃ¡c file `config.py`.
    - **`settings.py` (khai bÃ¡o tham sá»‘ mÃ´ hÃ¬nh)**:
        - Má»—i model project trong `ml-model-development/models/` sáº½ cÃ³ file `src/config.py`. File nÃ y sá»­ dá»¥ng Pydantic `BaseSettings` Ä‘á»ƒ load cáº¥u hÃ¬nh tá»« biáº¿n mÃ´i trÆ°á»ng, file `.env`, hoáº·c cÃ¡c nguá»“n khÃ¡c.
            
            Python
            
            ```
            # VÃ­ dá»¥: ml-model-development/models/fraud_detection_xgboost/src/config.py
            from pydantic_settings import BaseSettings
            from typing import List, Optional
            
            class FraudModelHyperparameters(BaseSettings):
                n_estimators: int = 100
                learning_rate: float = 0.1
                max_depth: int = 3
                # ... cÃ¡c HPs khÃ¡c
            
            class TrainingConfig(BaseSettings):
                mlflow_tracking_uri: str
                mlflow_experiment_name: str = "fraud_detection"
                feature_view_name: str = "fraud_transaction_features" # TÃªn FeatureView trong Feast
                label_column: str = "is_fraudulent"
                test_split_ratio: float = 0.2
                random_seed: int = 42
                hyperparameters: FraudModelHyperparameters = FraudModelHyperparameters()
            
                class Config:
                    env_prefix = "TRAINING_" # VÃ­ dá»¥: TRAINING_MLFLOW_TRACKING_URI
                    env_file = ".env" # Load tá»« file .env
                    # Cho phÃ©p load nested Pydantic models tá»« biáº¿n mÃ´i trÆ°á»ng
                    # VÃ­ dá»¥: TRAINING_HYPERPARAMETERS__N_ESTIMATORS=200
                    # ChÃº Ã½ dáº¥u "__" cho nested.
                    # Hoáº·c cÃ³ thá»ƒ parse tá»« JSON string náº¿u phá»©c táº¡p hÆ¡n.
            
            # Sá»­ dá»¥ng:
            # from .config import TrainingConfig
            # training_cfg = TrainingConfig()
            # print(training_cfg.hyperparameters.n_estimators)
            ```
            

Cáº¥u trÃºc nÃ y ráº¥t chi tiáº¿t vÃ  sáºµn sÃ ng cho viá»‡c triá»ƒn khai má»™t há»‡ thá»‘ng MLOps phá»©c táº¡p.
